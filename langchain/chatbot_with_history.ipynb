{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_groq.chat_models.ChatGroq'>\n"
     ]
    }
   ],
   "source": [
    "# open source model using GROQ api \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=\"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\"\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Tarun, it's nice to meet you!\\n\\nThat's a fantastic title ‚Äì Chief AI Engineer.  What kind of exciting projects are you working on? I'm always eager to learn more about the innovative things people are doing with AI.  \\n\\nPerhaps you could tell me:\\n\\n* **What industry are you in?** \\n* **What are some of the biggest challenges you face in your role?**\\n* **What are you most excited about for the future of AI?**\\n\\n\\nI'm ready to listen and learn!  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 24, 'total_tokens': 144, 'completion_time': 0.218181818, 'prompt_time': 0.000131949, 'queue_time': 0.013394251000000001, 'total_time': 0.218313767}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-95636d0f-e28a-45f5-a2d1-5af2a7d51145-0', usage_metadata={'input_tokens': 24, 'output_tokens': 120, 'total_tokens': 144})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is  tarun and i am a chief ai engineer\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your name is Tarun and you are a Chief AI Engineer. üòä \\n\\nIs there anything else I can help you with?\\n', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 67, 'total_tokens': 98, 'completion_time': 0.056363636, 'prompt_time': 0.002039432, 'queue_time': 0.012222278, 'total_time': 0.058403068}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1d77674-59ce-4be1-a44c-13158ac9edab-0', usage_metadata={'input_tokens': 67, 'output_tokens': 31, 'total_tokens': 98})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "         HumanMessage(content=\"Hi, my name is  tarun and i am a chief ai engineer\"),\n",
    "         AIMessage(content=\"Hi tarun nice to meet you and i am your ai asistent\"),\n",
    "         HumanMessage(content=\"Can you help me answer the following question, what was my name and what do i do?\")\n",
    "         \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Spain is **Madrid**. \\n', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 15, 'total_tokens': 27, 'completion_time': 0.021818182, 'prompt_time': 0.000773256, 'queue_time': 0.382347879, 'total_time': 0.022591438}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-930b98ba-ce75-4aa4-bade-55e1075771b0-0', usage_metadata={'input_tokens': 15, 'output_tokens': 12, 'total_tokens': 27})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\"what is the capital of spain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## message history bot in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] =ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history =RunnableWithMessageHistory(model,get_session_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is  tarun and i am a chief ai engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Tarun,\\n\\nIt's great to meet you! Being a Chief AI Engineer is a fascinating role. What kind of projects are you working on these days? \\n\\nI'm eager to learn more about your work and how AI is being applied in your field. üòä  \\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the config->change session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Tarun.  \\n\\nI remember that you introduced yourself earlier. üòä \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know! üòä  \\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is john cena\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is John Cena!  \\n\\nIt seems like you're trying to test me.  üòÑ  Do you have any other questions for me, John? \\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistent.answer all the questions\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "\n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Tarun! It's nice to meet you. \\n\\nIs there anything I can help you with today? üòä  \\n\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 26, 'total_tokens': 55, 'completion_time': 0.052727273, 'prompt_time': 0.0001346, 'queue_time': 0.014366079, 'total_time': 0.052861873}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c9e12ac2-b7ba-49f9-9537-49bad3aa1af3-0', usage_metadata={'input_tokens': 26, 'output_tokens': 29, 'total_tokens': 55})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":[HumanMessage(content=\"hi my name is tarun\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history =RunnableWithMessageHistory(chain,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is tarun\")],\n",
    "    config=config3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Tarun!  \\n\\nIt's nice to meet you. How can I help you today? üòä  \\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more complexity here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§§‡§æ‡§∞‡•Å‡§£!  üòä\\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistent.answer all the questions in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\"),\n",
    "       \n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n",
    "\n",
    "response=chain.invoke({\"language\":\"Hindi\",\"message\":[HumanMessage(content=\"hi my name is tarun\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history =RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§§‡§æ‡§∞‡•Å‡§®! \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config4={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"message\":[HumanMessage(content=\"hi,i am tarun\")],\"language\":\"Hindi\"},\n",
    "    config=config4\n",
    "\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nd\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# managing the conversation history for q/a chatbot\n",
    "'''\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Welcome to the Q&A chatbot! You will be given a question, and you must generate an appropriate answer.'),\n",
       " HumanMessage(content='What is the history of the Eiffel Tower?'),\n",
       " AIMessage(content='The Eiffel Tower was built between 1889 and 1889 for the 19th century French Exposition Universelle in Paris.')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"Welcome to the Q&A chatbot! You will be given a question, and you must generate an appropriate answer.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),\n",
    "    HumanMessage(content=\"Who was the first woman to win a Nobel Prize?\"),\n",
    "    AIMessage(content=\"The first woman to win a Nobel Prize was Marie Curie.\"),\n",
    "    HumanMessage(content=\"What is the history of the Eiffel Tower?\"),\n",
    "    AIMessage(content=\"The Eiffel Tower was built between 1889 and 1889 for the 19th century French Exposition Universelle in Paris.\")\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\onedrive\\gen ai codes and documents\\codes\\env\\lib\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§§‡§æ‡§∞‡•Å‡§£! üòä \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡•á ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ï‡§ø ‡§â‡§®‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á ‡§∏‡§ï‡•Ç‡§Å‡•§ \\n\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistent.answer all the questions in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\"),\n",
    "       \n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n",
    "\n",
    "response=chain.invoke({\"language\":\"Hindi\",\"message\":[HumanMessage(content=\"hi my name is tarun\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§§‡§æ‡§∞‡•Å‡§£! ‡§´‡•ç‡§∞‡§æ‡§Ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä **‡§™‡•á‡§∞‡§ø‡§∏** ‡§π‡•à‡•§  \\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"language\":\"Hindi\",\"message\":[HumanMessage(content=\"hi my name is tarun what is the capital of france\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§®‡•á \"what did i ask\" ‡§™‡•Ç‡§õ‡§æ ‡§π‡•à‡•§  \\n\\n‡§Ü‡§™ ‡§Ø‡§π ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ! \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§™‡§ø‡§õ‡§≤‡•á ‡§ï‡•Å‡§õ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•ã ‡§¶‡•ã‡§π‡§∞‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"message\":[HumanMessage(content=\"what did i ask\")],\"language\":\"Hindi\"},\n",
    "    config=config4\n",
    "\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
